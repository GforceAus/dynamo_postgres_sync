#+title: Dynamo Sync Tool

* Introduction
* Dev Log
** Table Indices
See [[file:indexes.org]].
** Table Schema
The =justfile= uses the =datamodel= tool, by =pydantic=, to generate schema's:

#+begin_src just
############################################################
## Get Schemas #############################################
############################################################
# Generate schema for Tasks (42 Seconds on Vale)
schema-tasks:
    mkdir -p models && \
    uv run --with datamodel-code-generator \
        datamodel-codegen \
        --input ./data/raw/GforceTasks-notow4pikzczbpjg42gytvbuci-production.json \
        --input-file-type json \
        --output models/tasks.py

# Generate schema for stores
schema-stores:
    mkdir -p models && \
    uv run --with datamodel-code-generator \
        datamodel-codegen \
        --input ./data/raw/GforceCallCycle-notow4pikzczbpjg42gytvbuci-production.json \
        --input-file-type json \
        --output models/stores.py

# Generate schema for call cycles
schema-call-cycles:
    mkdir -p models && \
    uv run --with datamodel-code-generator \
        datamodel-codegen \
        --input ./data/raw/GforceStore-notow4pikzczbpjg42gytvbuci-production.json \
        --input-file-type json \
        --output models/call_cycles.py

# Generate all schemas
schema-all: schema-tasks schema-stores schema-call-cycles
#+end_src
** Extract
The =extract= command downloads all data from Dynamo DB as a json file. It takes 10 minutes for 100k tasks. There is 90K tasks as of [2025-09-26 Fri] which is 300 MB. This assumes the data will fit in memory.
** Transform
*** Overview
**** First Approach
1. Create Classes using =datamodel-code-generator.datemodel-codegen=
2. Create a DuckDB Table for each class:
   #+begin_src python
import pyarrow as pa
import duckdb

# Convert to a PyArrow Table
arrays = [
    pa.array([d.id for d in data]),
    pa.array([d.name for d in data]),
    pa.array([d.age for d in data])
]
batch = pa.RecordBatch.from_arrays(arrays, names=['id', 'name', 'age'])

# Creating a DuckDB table
con = duckdb.connect(database=':memory:')
con.execute("CREATE TABLE my_data AS SELECT * FROM batch")

# Verify table creation
print(con.execute("SELECT * FROM my_data").fetchall())
   #+end_src
3. Print the Schema
   #+begin_src sql
.schema {table}
   #+end_src
4. Load the Data into a =_raw= table
   #+begin_src sql
CREATE TABLE stores_raw AS (SELECT * FROM read_json_auto('./data/raw/GforceStore-notow4pikzczbpjg42gytvbuci-production.json'));
CREATE TABLE task_raw AS (SELECT * FROM read_json_auto('./data/raw/GforceTasks-notow4pikzczbpjg42gytvbuci-production.json'));
CREATE TABLE call_cycle_raw AS (SELECT * FROM read_json_auto('./data/raw/GforceCallCycle-notow4pikzczbpjg42gytvbuci-production.json'));
   #+end_src
5. Normalize into new tables

**** Simpler Approach
1. Load the Data into a =_raw= table
   #+begin_src sh
duckdb data/all.duckdb
   #+end_src
   #+begin_src sql
CREATE TABLE stores_raw AS (SELECT * FROM read_json_auto('./data/raw/GforceStore-notow4pikzczbpjg42gytvbuci-production.json'));
CREATE TABLE task_raw AS (SELECT * FROM read_json_auto('./data/raw/GforceTasks-notow4pikzczbpjg42gytvbuci-production.json'));
CREATE TABLE call_cycle_raw AS (SELECT * FROM read_json_auto('./data/raw/GforceCallCycle-notow4pikzczbpjg42gytvbuci-production.json'));
   #+end_src
2. Get the types of each table
   #+begin_src sh
duckdb data/all.duckdb '.schema stores_raw'     >> ./data/models/raw.sql
duckdb data/all.duckdb '.schema call_cycle_raw' >> ./data/models/raw.sql
duckdb data/all.duckdb '.schema task_raw'       >> ./data/models/raw.sql
# Use sqlite format as duckdb is not supported
sql-formatter --fix -l sqlite  ./data/models/raw.sql
   #+end_src
3. Copy that file into a new SQL File that normalizes the types

   For example the =stores_raw= table is:

   #+begin_src sql
CREATE TABLE stores_raw (
  store_manager VARCHAR,
  support_rep_username VARCHAR,
  retailer_name VARCHAR,
  trade_drive_trough VARCHAR,
  visit_time VARCHAR,
  country VARCHAR,
  visit_days STRUCT ("name" VARCHAR, checked BOOLEAN) [],
  state VARCHAR,
  _version DOUBLE,
  territory VARCHAR,
  whare_sfs VARCHAR,
  additionalRep STRUCT (
    rep_cover VARCHAR,
    last_name VARCHAR,
    from_date VARCHAR,
    to_date VARCHAR,
    rep_cover_username VARCHAR,
    first_name VARCHAR
  ) [],
  region VARCHAR,
  id UUID,
  support_status VARCHAR,
  senior_rep_username VARCHAR,
  __typename VARCHAR,
  _lastChangedAt DOUBLE,
  store_grade VARCHAR,
  store_id VARCHAR,
  senior_status VARCHAR,
  contact STRUCT (
    "name" VARCHAR,
    "position" VARCHAR,
    phone VARCHAR,
    email VARCHAR
  ) [],
  createdAt VARCHAR,
  address VARCHAR,
  visit_freq VARCHAR,
  updatedAt VARCHAR,
  store_size VARCHAR,
  mob_number VARCHAR,
  store_manager_email VARCHAR,
  visit_start_week_no VARCHAR,
  store_name VARCHAR,
  store_status VARCHAR,
  notes STRUCT (datetime VARCHAR, notes VARCHAR) [],
  sales_status VARCHAR,
  sales_rep_notes STRUCT (datetime VARCHAR, notes VARCHAR) [],
  sales_rep_username VARCHAR
);
   #+end_src

   Consider the =visit_days STRUCT (...) []= field, this would be replaced with a table to join on:

   #+begin_src sql
CREATE TABLE store_visit_days (store_id VARCHAR, name VARCHAR, checked BOOLEAN);
   #+end_src

   If it was a single value rather than a list, then the new table would have an id field and the value in the table would have the corresponding id.
*** Type Mapping
The output data type for Stores looks like this:

#+begin_src python
# generated by datamodel-codegen:
#   filename:  GforceCallCycle-notow4pikzczbpjg42gytvbuci-production.json
#   timestamp: 2025-09-26T04:19:35+00:00

from __future__ import annotations

from typing import List, Optional

from pydantic import BaseModel, Field


class Store(BaseModel):
    store_id: str
    mins_per_visit: Optional[str] = None
    anotherDis: Optional[bool] = None
    supplier_username: Optional[str] = None
    store_name: str
    checked: bool
    disabled: bool
    label: str
    value: str
    frequency: str
    supplier: Optional[str] = None


class CountryItem(BaseModel):
    value: str
    label: str


class StateItem(BaseModel):
    value: str
    label: str


class ModelItem(BaseModel):
    field__typename: str = Field(..., alias='__typename')
    call_status: str
    field_lastChangedAt: float = Field(..., alias='_lastChangedAt')
    call_time: str
    end_date: str
    stores: List[Store]
    createdAt: str
    retailer: str
    call_cycle_name: str
    country: List[CountryItem]
    call_id: str
    state: List[StateItem]
    field_version: float = Field(..., alias='_version')
    call_cycle_freq: str
    start_date: str
    updatedAt: str
    supplier_username: str
    id: str
    supplier_name: str


class Model(BaseModel):
    __root__: List[ModelItem]

#+end_src

The normalized variant uses the ID of the connecting table:

#+begin_src sql
CREATE TABLE Store (
    store_id TEXT NOT NULL,
    mins_per_visit TEXT,
    anotherDis BOOLEAN,
    supplier_username TEXT,
    store_name TEXT,
    checked BOOLEAN,
    disabled BOOLEAN,
    label TEXT,
    value TEXT,
    frequency TEXT,
    supplier TEXT
);

CREATE TABLE Country (
    value TEXT,
    label TEXT
);

CREATE TABLE State (
    value TEXT,
    label TEXT
);

CREATE TABLE Item (
    call_status TEXT,
    lastChangedAt DOUBLE,
    call_time TEXT,
    end_date TEXT,
    store_id TEXT, --   <-------------------------------------
    createdAt TEXT,
    retailer TEXT,
    call_cycle_name TEXT,
    country_id TEXT, -- <--------------------------------------
    call_id TEXT,
    state_id TEXT, --   <---------------------------------------
    version DOUBLE,
    call_cycle_freq TEXT,
    start_date TEXT,
    updatedAt TEXT,
    supplier_username TEXT,
    id TEXT,
    supplier_name TEXT
);

#+end_src
